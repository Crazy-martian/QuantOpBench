Operator,GPU,Model,Precision,Layer_Name,M,N,K,Time_ms,TFLOPS/TOPS,GB/s
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,1,4096,4096,0.55681,0.06,30.168
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,16,4096,4096,6.50845,0.082,2.628
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,32,4096,4096,12.79848,0.084,1.362
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,64,4096,4096,25.26267,0.085,0.716
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,128,4096,4096,50.31095,0.085,0.386
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,256,4096,4096,106.52368,0.081,0.207
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,512,4096,4096,265.32105,0.065,0.103
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,1024,4096,4096,584.98559,0.059,0.065
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,2048,4096,4096,1186.59484,0.058,0.049
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,4096,4096,4096,2372.29469,0.058,0.042
torch,H800,Llama-3-8B,int8_int8_int32,Q-proj,8192,4096,4096,4710.6325,0.058,0.039
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,1,4096,1024,0.14292,0.059,29.468
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,16,4096,1024,1.65321,0.081,2.706
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,32,4096,1024,3.26696,0.082,1.454
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,64,4096,1024,6.42405,0.084,0.826
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,128,4096,1024,12.74481,0.084,0.504
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,256,4096,1024,25.43413,0.084,0.34
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,512,4096,1024,61.48659,0.07,0.213
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,1024,4096,1024,144.95247,0.059,0.152
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,2048,4096,1024,293.18729,0.059,0.136
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,4096,4096,1024,577.89418,0.059,0.131
torch,H800,Llama-3-8B,int8_int8_int32,KV-proj,8192,4096,1024,1174.69516,0.058,0.125
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,1,14336,4096,2.07022,0.057,28.394
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,16,14336,4096,22.75622,0.083,2.624
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,32,14336,4096,44.76756,0.084,1.356
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,64,14336,4096,88.85353,0.085,0.705
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,128,14336,4096,199.94086,0.075,0.333
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,256,14336,4096,485.50277,0.062,0.153
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,512,14336,4096,989.0243,0.061,0.091
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,1024,14336,4096,1984.83938,0.061,0.061
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,2048,14336,4096,3972.11,0.061,0.046
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,4096,14336,4096,8547.53563,0.056,0.036
torch,H800,Llama-3-8B,int8_int8_int32,FFN Up-proj,8192,14336,4096,28707.3275,0.034,0.02
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,1,4096,14336,2.02152,0.058,29.063
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,16,4096,14336,22.66887,0.083,2.612
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,32,4096,14336,44.51808,0.084,1.341
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,64,4096,14336,88.29257,0.085,0.687
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,128,4096,14336,176.05387,0.085,0.356
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,256,4096,14336,353.4784,0.085,0.188
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,512,4096,14336,864.63664,0.07,0.086
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,1024,4096,14336,2026.22828,0.059,0.045
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,2048,4096,14336,4047.68062,0.059,0.03
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,4096,4096,14336,8171.66125,0.059,0.023
torch,H800,Llama-3-8B,int8_int8_int32,FFN Down-proj,8192,4096,14336,16229.06875,0.059,0.019
