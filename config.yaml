# 1. 定义测试环境
target_gpus:
  "A800": "nvidia/nvidia-a100"
  "H800": "nvidia/nvidia-h100"

# 2. 定义模型层级的矩阵尺寸 (N, K)
models:
    # "Layer Name": [N, K]
  "Llama-3-8B":
    "Q-proj": [4096, 4096]
    "KV-proj": [4096, 1024]
    "FFN Up-proj": [14336, 4096]
    "FFN Down-proj": [4096, 14336]
  "Llama-3-70B":
    "Q-proj": [8192, 8192]
    "KV-proj": [8192, 1024]
    "FFN Up-proj": [28672, 8192]
    "FFN Down-proj": [8192, 28672]

# 3. 定义量化精度
#    格式为[W_dtype, A_dtype, out_dtype]
precisions:
  # - ["float16", "float16", "float16"]  # Baseline
  - ["int4", "float16", "float16"]     # W4A16
  # - ["int8", "int8", "int32"]          # W8A8

# 4. 定义M的大小
#    直接枚举M，省略了由batch size和sequence length计算得到
M:
  - 1
  - 16
  - 32
  - 64
  - 128
  - 256
  - 512
  - 1024
  - 2048
  - 4096
  - 8192

operators:
  - "bitblas"
  # - "torch"